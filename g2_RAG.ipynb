{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def00bdd-5671-4e84-8c1d-28b551b485ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jj/miniconda3/envs/group2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  7.24it/s]\n",
      "/tmp/ipykernel_356911/202386331.py:59: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1/2\n",
      "Processed batch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Relevant text chunk:\n",
      "Figure 1. System flow chart\n",
      "The following is a detailed description of each function.\n",
      "- User interface: Users can operate through the interface and scan their hands through the camera. When not in \n",
      "use, the user can cancel the operation through the interface button, as shown in Figure 2.\n",
      "Translated from Chinese (Simplified) to English - www.onlinedoctranslator.com Figure 2: User Interface\n",
      "- Image recognition real-time data processing: The images generated by the scan are processed by the system \n",
      "MediapipeImage recognition analyzes the palm, identifies the points at the finger joints and connects the two \n",
      "points into a line, calculates the joint angles and generates data, as shown in Figure 3.\n",
      "Figure 3MediapipeImage recognition (the numbers in the figure are the bending angles)\n",
      "- Remote control: Utilizing data generated by image recognitionWi-FiBy performing wireless remote \n",
      "transmission, users can perform contactless operations regardless of the distance, as shown in Figure 4.\n",
      "Figure 4: Remote control example (right isMediapipe, leftArduinoConnector Chip) - Robot synchronization: The received data is used to control the robot so that it can accurately imitate \n",
      "the user's hand and synchronize its movements, as shown in Figure 5.\n",
      "Figure 5. Robot synchronization example\n",
      "In general, the system covers four core functions: user interface, image recognition real-time data processing, \n",
      "remote control and robot synchronization. Users can scan their hands through the interface, and the system uses\n",
      "MediapipeIt performs image recognition, calculates joint angles, and transmits data wirelessly to a remote location, \n",
      "controlling the robot to synchronize the user's hand movements. This system enables contactless remote control, \n",
      "perfectly combining image processing technology with mechanical movements.\n",
      "4. System Features\n",
      "The feature of this system is that the data generated by image recognition is transmitted to the remote end through\n",
      "\n",
      "Relevant text chunk:\n",
      "Appendix 1-1: System Overview Document\n",
      "No.:\n",
      "Chinese Topic Title:Robert hand— Remote Wireless Synchronization Smart Phone English \n",
      "Title:Robert Hand— Remote Wireless Synchronized Smart Hand\n",
      "1. Introduction\n",
      "In the past few years, the COVID-19 pandemic has had a severe impact on the global medical system, especially for \n",
      "medical personnel, who have increased the risk of infection by coming into close contact with patients for rapid screening or \n",
      "treatment. At the same time, we have been paying attention to the news and found that in recent years, there have been many \n",
      "cases of firefighters dying in the line of duty, as well as injuries or accidental deaths caused by police officers while performing \n",
      "arrests and other duties, which shows that in emergency work environments, the risk of injury or accidents cannot be ignored. \n",
      "Therefore, we began to explore how to reduce direct contact and use technology to improve work safety and efficiency.\n",
      "2. Creative Description\n",
      "This system aims to achieve precise remote control of robot movements through image recognition \n",
      "technology and wireless transmission technology. The user scans his hand movements through the camera, \n",
      "and the system calculates the finger joint angles in real time and transmits the data wirelessly toArduinoWe \n",
      "believe that this technology can be widely used in medical, high-risk environments, industrial automation, \n",
      "etc. It can improve work quality and work environment by remotely operating through image recognition.\n",
      "3. System Function Introduction\n",
      "The functions of this system can be divided into four categories: user interface, image recognition real-time data \n",
      "processing, remote control and robot synchronization. The system flow is shown in Figure 1.\n",
      "Figure 1. System flow chart\n",
      "The following is a detailed description of each function.\n",
      "- User interface: Users can operate through the interface and scan their hands through the camera. When not in\n",
      "\n",
      "Relevant text chunk:\n",
      "4. System Features\n",
      "The feature of this system is that the data generated by image recognition is transmitted to the remote end through \n",
      "wireless transmission. The user can ignore the distance limit and can control the robot by simply showing the action in front of \n",
      "the camera. Remote operation can reduce the risk of infection and injury to the operator and improve work safety. Wireless \n",
      "transmission brings real-time performance to this system. The system has low latency and can reflect hand movements to the \n",
      "robot in real time. Therefore, this system can accurately synchronize the user's hand movements. Through hand movement \n",
      "capture technology, image analysis can calculate the bending angle of each finger joint in a very short time, achieving accuracy. \n",
      "Coupled with the low latency of the system, it ensures that the robot can accurately imitate the user's hand movements.\n",
      "5. System Development Tools and Technologies\n",
      "This system can be divided into three parts according to the development tools: software, hardware, and communication.\n",
      "-\n",
      "-\n",
      "-\n",
      "Software:Mediapipe,Arduino IDE Hardware:ArduinoChip, \n",
      "hardware equipment, robot communication:Wi-FiWireless \n",
      "network transmission\n",
      "We choosePythonAs a development language for image recognition technology,PythonThe flexibility of \n",
      "the platform allows us to quickly develop and program computations.MediapipeThe suite analyzes image data.\n",
      "MediapipeAs a powerful image recognition framework, it can help us process the image data of hand \n",
      "movements in real time. This system uses the hand tracking module to accurately obtain the finger joint angles \n",
      "and store the angles in an array for encryption and simplified processing. The encrypted data is then sent to the\n",
      "socketTransfer toArduino, simplifying the data transmission and processing process.\n",
      "existArduino IDEIn this tutorial, we write a program to control the robot.ArduinoAs the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_356911/202386331.py:102: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import chromadb\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True,max_split_size_mb:512\"\n",
    "torch.backends.cuda.max_split_size_mb = 512\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def process_pdf(pdf_file_path, batch_size=4):\n",
    "   loader = PyPDFLoader(pdf_file_path)\n",
    "   pages = loader.load()\n",
    "   text = \" \".join([page.page_content for page in pages])\n",
    "   \n",
    "   text_splitter = RecursiveCharacterTextSplitter(\n",
    "       chunk_size=2000,\n",
    "       chunk_overlap=200,\n",
    "       length_function=len,\n",
    "       separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "   )\n",
    "   chunks = text_splitter.split_text(text)\n",
    "   \n",
    "   model_path = \"/home/jj/G2_Llama-3.1/\"\n",
    "   tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "   tokenizer.pad_token = tokenizer.eos_token\n",
    "   \n",
    "   model = AutoModel.from_pretrained(\n",
    "       model_path,\n",
    "       torch_dtype=torch.bfloat16,\n",
    "       low_cpu_mem_usage=True,\n",
    "   ).to(device)\n",
    "   \n",
    "   model.config.pad_token_id = tokenizer.pad_token_id\n",
    "   model.gradient_checkpointing_enable()\n",
    "   \n",
    "   embeddings_list = []\n",
    "   \n",
    "   try:\n",
    "       for i in range(0, len(chunks), batch_size):\n",
    "           torch.cuda.empty_cache()\n",
    "           gc.collect()\n",
    "           \n",
    "           batch_chunks = chunks[i:i + batch_size]\n",
    "           inputs = tokenizer(\n",
    "               batch_chunks,\n",
    "               return_tensors=\"pt\",\n",
    "               padding=True,\n",
    "               truncation=True,\n",
    "               max_length=256\n",
    "           ).to(device)\n",
    "           \n",
    "           with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "               outputs = model(**inputs)\n",
    "               batch_embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "               batch_embeddings = batch_embeddings.cpu()\n",
    "               embeddings_list.append(batch_embeddings)\n",
    "           \n",
    "           del outputs\n",
    "           del inputs\n",
    "           torch.cuda.empty_cache()\n",
    "           \n",
    "           print(f\"Processed batch {i//batch_size + 1}/{len(chunks)//batch_size + 1}\")\n",
    "           \n",
    "   except RuntimeError as e:\n",
    "       print(f\"Error during processing: {e}\")\n",
    "       return None, None\n",
    "       \n",
    "   embeddings = torch.cat(embeddings_list, dim=0)\n",
    "   return embeddings, chunks\n",
    "\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(\"pdf_embeddings\")\n",
    "\n",
    "pdf_file_path = \"/home/jj/Downloads/G2/Hand-Introduction_English.pdf\"\n",
    "embeddings, chunks = process_pdf(pdf_file_path, batch_size=4)\n",
    "\n",
    "for i, embedding in enumerate(embeddings):\n",
    "   embedding_list = embedding.detach().numpy().flatten().tolist()\n",
    "   collection.add(\n",
    "       embeddings=[embedding_list],\n",
    "       documents=[chunks[i]],\n",
    "       ids=[f\"chunk_{i}\"]\n",
    "   )\n",
    "\n",
    "query = \"What is the technical core of this system??\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/jj/G2_Llama-3.1/\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModel.from_pretrained(\n",
    "   \"/home/jj/G2_Llama-3.1/\",\n",
    "   torch_dtype=torch.bfloat16,\n",
    "   low_cpu_mem_usage=True,\n",
    ").to(device)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "   query_inputs = tokenizer(\n",
    "       query,\n",
    "       return_tensors=\"pt\",\n",
    "       padding=True,\n",
    "       truncation=True,\n",
    "       max_length=256\n",
    "   ).to(device)\n",
    "   query_outputs = model(**query_inputs)\n",
    "   query_embedding = query_outputs.last_hidden_state.mean(dim=1).cpu()\n",
    "   \n",
    "query_embedding_list = query_embedding.detach().numpy().flatten().tolist()\n",
    "\n",
    "results = collection.query(\n",
    "   query_embeddings=[query_embedding_list],\n",
    "   n_results=3\n",
    ")\n",
    "\n",
    "for doc in results['documents'][0]:\n",
    "   print(\"\\nRelevant text chunk:\")\n",
    "   print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd4df13-9119-40a8-83ba-182415b1411b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
